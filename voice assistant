import os
import time
import asyncio
import queue
import threading
import numpy as np
import sounddevice as sd
import scipy.io.wavfile as wavfile
import edge_tts
import pygame
import io
import re
from groq import Groq

# =================== CONFIGURATION ===================
GROQ_API_KEY = "api key " 
MODEL = "llama-3.3-70b-versatile"
SAMPLE_RATE = 16000
SILENCE_LIMIT = 1.3  # Reduced for snappier response

client = Groq(api_key=GROQ_API_KEY)

# Initialize Pygame properly
pygame.quit() # Reset any existing instance
pygame.init()
pygame.mixer.init(frequency=SAMPLE_RATE)

# Global flag for interruption
stop_audio = threading.Event()

# =================== LANGUAGE & VOICE ENGINE ===================

def detect_language_and_voice(text):
    """Checks if text is Tamil or English and returns correct voice"""
    tamil_chars = len(re.findall(r'[\u0b80-\u0bff]', text))
    if tamil_chars > 0:
        return "ta-IN-PallaviNeural"
    return "en-US-AvaNeural"

async def get_audio_data(text):
    """Fetches audio bytes from Edge-TTS"""
    voice = detect_language_and_voice(text)
    communicate = edge_tts.Communicate(text, voice, rate="+0%")
    audio_data = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data += chunk["data"]
    return audio_data

def play_audio_thread(audio_bytes):
    """Plays audio from bytes using a clean buffer"""
    try:
        stop_audio.clear()
        # Using a temporary buffer for playback stability
        buffer = io.BytesIO(audio_bytes)
        pygame.mixer.music.load(buffer)
        pygame.mixer.music.play()
        
        while pygame.mixer.music.get_busy():
            if stop_audio.is_set():
                pygame.mixer.music.stop()
                break
            time.sleep(0.05)
        buffer.close()
    except Exception as e:
        print(f"Playback Error: {e}")

def speak(text):
    """Main Speak Function: Terminal -> Voice"""
    print(f"\nJarvis: {text}")
    
    # Run async TTS fetch in a temporary loop to avoid conflict
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        audio_bytes = loop.run_until_complete(get_audio_data(text))
        loop.close()
        
        # Start playback in a daemon thread
        threading.Thread(target=play_audio_thread, args=(audio_bytes,), daemon=True).start()
    except Exception as e:
        print(f"TTS Error: {e}")

# =================== BRAIN & HEARING ===================

def get_jarvis_response(user_text):
    try:
        completion = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "You are Jarvis for Mukil. Rule: If he speaks Tamil, reply in Tamil script. If English, reply in English. Be cool, use 'Mapla'."},
                {"role": "user", "content": user_text}
            ],
            model=MODEL,
        )
        return completion.choices[0].message.content
    except Exception as e:
        return "Brain-la error mapla."

def transcribe_with_groq(audio_np_array):
    """Sends recorded data to Groq via RAM buffer"""
    buffer = io.BytesIO()
    wavfile.write(buffer, SAMPLE_RATE, (audio_np_array * 32767).astype(np.int16))
    buffer.name = "voice.wav"
    buffer.seek(0)
    try:
        return client.audio.transcriptions.create(file=buffer, model="whisper-large-v3", response_format="text")
    except: return ""

# =================== LISTENING LOGIC ===================

def listen_hands_free():
    audio_q = queue.Queue()
    def callback(indata, frames, time, status): audio_q.put(indata.copy())

    # Monitor mic with SoundDevice
    with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, callback=callback):
        print("\nğŸ¤ Listening...")
        recorded_data, is_speaking, silence_start = [], False, None

        while True:
            chunk = audio_q.get()
            vol = np.linalg.norm(chunk) * 10
            
            if vol > 0.5: # Threshold adjusted to 0.5 to prevent random noise triggers
                if not is_speaking:
                    stop_audio.set() # Stop Jarvis if you interrupt
                is_speaking = True
                recorded_data.append(chunk)
                silence_start = None
            elif is_speaking:
                recorded_data.append(chunk)
                if silence_start is None: silence_start = time.time()
                if time.time() - silence_start > SILENCE_LIMIT: break
        
        if recorded_data:
            return transcribe_with_groq(np.concatenate(recorded_data))
        return ""

# =================== RUN ===================

if __name__ == "__main__":
    # Pointing out a mistake Mukil: You keep pasting your key. 
    # I've used a placeholder. Please paste your key carefully.
    speak("System Check Complete mapla. Tamil and English voices ready. Audio files removed. Sollu mapla!")
    
    while True:
        try:
            user_msg = listen_hands_free()
            if user_msg and len(user_msg.strip()) > 1:
                print(f"You: {user_msg}")
                
                # Check for shutdown commands in both languages
                if any(x in user_msg.lower() for x in ["exit", "bye", "shutdown", "à®•à®¿à®³à®®à¯à®ªà¯à®±à¯‡à®©à¯", "à®ªà¯‹à®¯à®¿à®Ÿà¯à®Ÿà¯ à®µà®°à¯‡à®©à¯"]):
                    speak("Sari mapla, take care. Catch you later!")
                    time.sleep(2)
                    break
                
                reply = get_jarvis_response(user_msg)
                speak(reply)
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"Restarting Listener... Error: {e}")
            time.sleep(1)
